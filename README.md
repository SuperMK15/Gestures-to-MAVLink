# Hand-Gesture-Drone
# âœ‹ğŸ›¸ Drone Control via Hand Gestures (MediaPipe + OpenCV)

This project enables **gesture-based drone control** using real-time webcam input and **MediaPipe Hands**. Control a drone by simply moving your hands â€” no controllers or voice required!

---

## âœ¨ Features

- ğŸ–ï¸ **Hand Gesture Detection** â€“ Uses MediaPipe to detect and classify hand gestures.
- ğŸ® **Gesture-to-Command Mapping** â€“ Predefined gestures translate directly to drone actions.
- ğŸš **Drone API Integration** â€“ Commands are executed through a MAVLink-compatible drone interface.
- ğŸ“¹ **Live Webcam Feed** â€“ Visual feedback and action overlays shown in real-time.
- âœ… **Safety Checks** â€“ Commands are only triggered if gestures persist for over 1 second.

---

## âœ‹ Supported Gestures

| Left Hand       | Right Hand      | Drone Action                        |
|-----------------|------------------|-------------------------------------|
| âœŒï¸ Peace Sign   | âœŒï¸ Peace Sign   | Takeoff                             |
| âœŠ Fist          | âœŠ Fist          | Return to Launch (RTL)              |
| ğŸ–ï¸ Open Palm   | ğŸ–ï¸ Open Palm   | Fly Forwards                        |
| âœŒï¸ Peace Sign   | ğŸ–ï¸ Open Palm   | Fly Forwards + Yaw Left             |
| ğŸ–ï¸ Open Palm   | âœŒï¸ Peace Sign   | Fly Forwards + Yaw Right            |
| âœŠ Fist          | ğŸ–ï¸ Open Palm   | Fly Left                            |
| ğŸ–ï¸ Open Palm   | âœŠ Fist          | Fly Right                           |
| âœŒï¸ Peace Sign   | ---          | Yaw Left    |
| ---             | âœŒï¸ Peace Sign | Yaw Right    |
| âœŠ Fist          | ---          | Fly Down       |
| ---          | âœŠ Fist          | Fly Up       |
| ğŸ–ï¸ Open Palm   | ---         | Fly Forwards                        |
| ---   | ğŸ–ï¸ Open Palm         | Fly Forwards                        |

---

## âš™ï¸ How It Works

1. Launch the system using your webcam.
2. The program detects hand landmarks using MediaPipe.
3. Hand poses (open palm, fist, peace sign) are classified per hand.
4. If a valid gesture is held for more than one second, the corresponding drone command is executed.
5. Visual feedback is provided via OpenCV.

---

## ğŸ“¦ Modules

- `drone.py` â€“ Abstraction layer for MAVLink drone commands (arm, takeoff, movement, yaw, RTL).
- `gestures.py` â€“ Classifies finger status and maps them to predefined gestures.
- `configs.py` â€“ Loads drone-specific configuration like connection strings and speeds.

---

## ğŸ§­ Example Commands

- **Takeoff** â†’ âœŒï¸ + âœŒï¸
- **Fly Forward** â†’ ğŸ–ï¸ + ğŸ–ï¸
- **Yaw Left** â†’ âœŒï¸ (Left hand only)
- **Fly Up** â†’ âœŠ (Right hand only)
- **RTL (Return to Launch)** â†’ âœŠ + âœŠ

---

## ğŸ› ï¸ Requirements

- Python 3.7+
- Webcam
- Recommended Python packages:
  - `mediapipe`
  - `opencv-python`
  - `pymavlink`
- See [requirements.txt](./requirements.txt) for more!

---
## ğŸš€ Getting Started

1. Clone the repo:
   ```bash
   git clone https://github.com/SuperMK15/Gestures-to-MAVLink.git
   cd Gestures-to-MAVLink
   ```

2. Create `venv` and install dependencies:
   ```bash
   python -m venv venv
   ./venv/bin/activate
   pip install -r requirements.txt
   ```

3. Start MAVLink forwarding from Mission Planner (or whatever GCS software you use) and modify the drone connection string inside [drone.yaml](./configs/drone.yaml) accordingly:
   ```yaml
   connection_string: "tcp:127.0.0.1:14550"
   ```

4. Run [main.py](./main.py):
   ```bash
   python main.py
   ```

---
## âš ï¸ Disclaimer
- Always test indoors with props removed or in a safe simulation environment first. Ensure safety protocols are in place when flying a real drone.